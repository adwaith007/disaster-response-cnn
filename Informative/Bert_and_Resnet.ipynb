{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert and Resnet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc_rI6d-khY2",
        "outputId": "d9a0d849-376f-4f6e-df31-d54f28380952"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzejvNI6kk3A"
      },
      "source": [
        "!pip3 install torch torchvision pandas transformers scikit-learn tensorflow numpy seaborn matplotlib textwrap3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrBErHTyknRL",
        "outputId": "fb9a18fe-cd0c-488b-d544-02f64ff1a7ab"
      },
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9plONFGko6I"
      },
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r\"@[A-Za-z0-9_]+\", ' ', text)\n",
        "    text = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', text)\n",
        "    text = re.sub(r\"[^a-zA-z.,!?'0-9]\", ' ', text)\n",
        "    text = re.sub('\\t', ' ',  text)\n",
        "    text = re.sub(r\" +\", ' ', text)\n",
        "    return text\n",
        "\n",
        "def label_to_target(text):\n",
        "  if text == \"informative\":\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "df_train = pd.read_csv(\"./gdrive/MyDrive/Models/train.tsv\", sep='\\t')\n",
        "df_train = df_train[['image', 'tweet_text', 'label_text']]\n",
        "df_train = df_train.sample(frac=1, random_state = 24).reset_index(drop=True)\n",
        "df_train['tweet_text'] = df_train['tweet_text'].apply(clean_text)\n",
        "df_train['label_text'] = df_train['label_text'].apply(label_to_target)\n",
        "\n",
        "df_val = pd.read_csv(\"./gdrive/MyDrive/Models/val.tsv\", sep='\\t')\n",
        "df_val = df_val[['image', 'tweet_text', 'label_text']]\n",
        "df_val = df_val.sample(frac=1, random_state = 24).reset_index(drop=True)\n",
        "df_val['tweet_text'] = df_val['tweet_text'].apply(clean_text)\n",
        "df_val['label_text'] = df_val['label_text'].apply(label_to_target)\n",
        "\n",
        "df_test = pd.read_csv(\"./gdrive/MyDrive/Models/test.tsv\", sep='\\t')\n",
        "df_test = df_test[['image', 'tweet_text', 'label_text']]\n",
        "df_test = df_test.sample(frac=1, random_state = 24).reset_index(drop=True)\n",
        "df_test['tweet_text'] = df_test['tweet_text'].apply(clean_text)\n",
        "df_test['label_text'] = df_test['label_text'].apply(label_to_target)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOjM9tz8ksnJ"
      },
      "source": [
        "data_dir = \"./gdrive/MyDrive/\"\n",
        "class DisasterTweetDataset(Dataset):\n",
        "\n",
        "  def __init__(self, tweets, targets, paths, tokenizer, max_len):\n",
        "    self.tweets = tweets\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "    self.paths = paths\n",
        "    self.transform = transforms.Compose([\n",
        "        transforms.Resize(size=256),\n",
        "        transforms.CenterCrop(size=224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.tweets)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    tweet = str(self.tweets[item])\n",
        "    target = self.targets[item]\n",
        "    path = str(self.paths[item])\n",
        "    img = Image.open(data_dir+self.paths[item]).convert('RGB')\n",
        "    img = self.transform(img)  \n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      tweet,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      padding='max_length',\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "      truncation = True\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'tweet_text': tweet,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long),\n",
        "      'tweet_image': img\n",
        "    }\n",
        "\n",
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = DisasterTweetDataset(\n",
        "    tweets=df.tweet_text.to_numpy(),\n",
        "    targets=df.label_text.to_numpy(),\n",
        "    paths=df.image.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=2\n",
        "  )\n",
        "\n",
        "\n",
        "class TweetClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(TweetClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "    for param in self.bert.parameters():\n",
        "      param.requires_grad = False\n",
        "    \n",
        "    self.resnet = torchvision.models.resnet18(pretrained=True)\n",
        "    for param in self.resnet.parameters():\n",
        "      param.requires_grad = False\n",
        "    \n",
        "    self.bn = nn.BatchNorm1d(self.bert.config.hidden_size + 1000)\n",
        "\n",
        "    self.linear1 = nn.Linear(self.bert.config.hidden_size + 1000, 1000)\n",
        "    self.relu1    = nn.ReLU()\n",
        "    self.dropout1 = nn.Dropout(p=0.4)\n",
        "\n",
        "    self.linear2 = nn.Linear(1000, 500)\n",
        "    self.relu2    = nn.ReLU()\n",
        "    self.dropout2 = nn.Dropout(p=0.2)\n",
        "\n",
        "    self.linear3 = nn.Linear(500, 250)\n",
        "    self.relu3    = nn.ReLU()\n",
        "    self.dropout3 = nn.Dropout(p=0.1)\n",
        "\n",
        "    self.linear4 = nn.Linear(250, 125)\n",
        "    self.relu4    = nn.ReLU()\n",
        "    self.dropout4 = nn.Dropout(p=0.02)\n",
        "\n",
        "    self.linear5 = nn.Linear(125, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask, tweet_img):\n",
        "    _, text_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      return_dict=False\n",
        "    )\n",
        "    image_output = self.resnet(tweet_img)\n",
        "    merged_output = torch.cat((text_output, image_output), dim=1)\n",
        "    bn_output = self.bn(merged_output)\n",
        "\n",
        "    linear1_output = self.linear1(bn_output)\n",
        "    relu1_output = self.relu1(linear1_output)\n",
        "    dropout1_output = self.dropout1(relu1_output)\n",
        "\n",
        "    linear2_output = self.linear2(dropout1_output)\n",
        "    relu2_output = self.relu2(linear2_output)\n",
        "    dropout2_output = self.dropout2(relu2_output)\n",
        "\n",
        "    linear3_output = self.linear3(dropout2_output)\n",
        "    relu3_output = self.relu3(linear3_output)\n",
        "    dropout3_output = self.dropout3(relu3_output)\n",
        "\n",
        "    linear4_output = self.linear4(dropout3_output)\n",
        "    relu4_output = self.relu4(linear4_output)\n",
        "    dropout4_output = self.dropout4(relu4_output)\n",
        "\n",
        "    linear5_output = self.linear5(dropout4_output)\n",
        "\n",
        "\n",
        "    probas = self.sigmoid(linear5_output)\n",
        "    return probas\n",
        "\n",
        "\n",
        "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  \n",
        "  for d in data_loader:\n",
        "    tweet_imgs = d[\"tweet_image\"].to(device)\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].reshape(-1, 1).float()\n",
        "    targets = targets.to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      tweet_img = tweet_imgs\n",
        "    )\n",
        "\n",
        "\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(torch.round(outputs) == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)\n",
        "\n",
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      tweet_imgs = d[\"tweet_image\"].to(device)\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].reshape(-1, 1).float()\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        tweet_img = tweet_imgs\n",
        "      )\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(torch.round(outputs) == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP2k2wgLkyo2"
      },
      "source": [
        "BATCH_SIZE = 512\n",
        "MAX_LEN = 150\n",
        "\n",
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "\n",
        "\n",
        "model = TweetClassifier()\n",
        "model = model.to(device)\n",
        "\n",
        "EPOCHS = 50\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.BCELoss().to(device)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CK6j-pnDk1d6",
        "outputId": "b3a151fa-a034-4bca-c9fe-cb5c292d09ff"
      },
      "source": [
        "history = defaultdict(list)\n",
        "start_epoch = 0\n",
        "best_accuracy = -1\n",
        "\n",
        "checkpoint = torch.load(\"./gdrive/MyDrive/Models/BertResNet/checkpoint.t7\")\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "start_epoch = checkpoint['epoch']\n",
        "best_accuracy = checkpoint['best_accuracy']\n",
        "\n",
        "print(start_epoch)\n",
        "print(best_accuracy)\n",
        "\n",
        "\n",
        "# for epoch in range(EPOCHS):\n",
        "\n",
        "#   print(f'Epoch {start_epoch + epoch + 1}/{start_epoch + EPOCHS}')\n",
        "#   print('-' * 10)\n",
        "\n",
        "#   train_acc, train_loss = train_epoch(\n",
        "#     model,\n",
        "#     train_data_loader,    \n",
        "#     loss_fn, \n",
        "#     optimizer, \n",
        "#     device, \n",
        "#     scheduler, \n",
        "#     len(df_train)\n",
        "#   )\n",
        "\n",
        "#   print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "#   val_acc, val_loss = eval_model(\n",
        "#     model,\n",
        "#     val_data_loader,\n",
        "#     loss_fn, \n",
        "#     device, \n",
        "#     len(df_val)\n",
        "#   )\n",
        "\n",
        "#   print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "#   print()\n",
        "\n",
        "#   history['train_acc'].append(train_acc)\n",
        "#   history['train_loss'].append(train_loss)\n",
        "#   history['val_acc'].append(val_acc)\n",
        "#   history['val_loss'].append(val_loss)\n",
        "\n",
        "#   if val_acc > best_accuracy:\n",
        "#     state = {\n",
        "#             'best_accuracy': val_acc,\n",
        "#             'epoch': start_epoch+epoch+1,\n",
        "#             'state_dict': model.state_dict(),\n",
        "#             'optimizer': optimizer.state_dict(),\n",
        "#     }\n",
        "#     savepath= \"./gdrive/MyDrive/Models/BertResNet/checkpoint.t7\"\n",
        "#     torch.save(state,savepath)\n",
        "#     best_accuracy = val_acc"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39\n",
            "tensor(0.8786, device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGFmTSaxYMw-"
      },
      "source": [
        "state = {\n",
        "        'epoch': start_epoch + EPOCHS,\n",
        "        'state_dict': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "}\n",
        "savepath= \"./gdrive/MyDrive/Models/BertResNet/checkpoint-{}.t7\".format(start_epoch + EPOCHS)\n",
        "torch.save(state,savepath)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScOj15BovCww",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "96f2dcd3-2554-4157-8847-17ba65146aaa"
      },
      "source": [
        "plt.plot(history['train_acc'], label='train accuracy')\n",
        "plt.plot(history['val_acc'], label='validation accuracy')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTghsXN8vEpo",
        "outputId": "67a127c2-7436-4c5f-fd16-f23d500d9acb"
      },
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  \n",
        "  predictions = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      tweet_imgs = d[\"tweet_image\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].reshape(-1, 1).float()\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        tweet_img = tweet_imgs\n",
        "      )\n",
        "      preds = torch.round(outputs)\n",
        "\n",
        "\n",
        "      predictions.extend(preds)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return predictions, real_values\n",
        "\n",
        "y_pred, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=['Not Informative', 'Informative'], digits=4))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Not Informative     0.8298    0.7738    0.8008       504\n",
            "    Informative     0.8929    0.9223    0.9074      1030\n",
            "\n",
            "       accuracy                         0.8735      1534\n",
            "      macro avg     0.8613    0.8481    0.8541      1534\n",
            "   weighted avg     0.8721    0.8735    0.8724      1534\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}