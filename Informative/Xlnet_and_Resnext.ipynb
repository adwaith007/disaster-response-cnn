{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Xlnet_and_Resnext.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"149ec9649d3640729f927cd8b2e7f8ae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a4fbbae186f846df907c6a200b6dcae2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_25ad982f015844cd9cc97d406b3493b5","IPY_MODEL_b8ce4b78d5984915bf6409bea2b96401"]}},"a4fbbae186f846df907c6a200b6dcae2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"25ad982f015844cd9cc97d406b3493b5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5dd76a394a384d41ac7bacb410513b44","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":798011,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":798011,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d26ec7e15f4e4ba5805f754e1d6e9b62"}},"b8ce4b78d5984915bf6409bea2b96401":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e6ef0e175aa64da48c8d0c5ef73c1876","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 798k/798k [00:13&lt;00:00, 57.8kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4a4c69b3a177490da45a8c4d0d4c4b6c"}},"5dd76a394a384d41ac7bacb410513b44":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d26ec7e15f4e4ba5805f754e1d6e9b62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e6ef0e175aa64da48c8d0c5ef73c1876":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4a4c69b3a177490da45a8c4d0d4c4b6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"03c58a1b5c9944cd9233b2365693b83c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_05d29521c6624f1b9cc5e826fbbe2fbd","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ed91a558915b424f8ff9a824479b8d1b","IPY_MODEL_f501f0cee75b43ac89759f09a43f8799"]}},"05d29521c6624f1b9cc5e826fbbe2fbd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ed91a558915b424f8ff9a824479b8d1b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d08e9fb278324b25ae052c1bd5e07f33","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1382015,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1382015,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_12588739dc044ea5adc790589f0fa6b9"}},"f501f0cee75b43ac89759f09a43f8799":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_df03682c782c49cf88217f08273963f4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.38M/1.38M [00:00&lt;00:00, 2.00MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9e34216ef18f40bf88c1f6e8fa790dfb"}},"d08e9fb278324b25ae052c1bd5e07f33":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"12588739dc044ea5adc790589f0fa6b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"df03682c782c49cf88217f08273963f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9e34216ef18f40bf88c1f6e8fa790dfb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fb1413e27a02414fb8cf45f10c995964":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c7e76e76bfde4b4bb290e4ad44b2cbb3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5f0c7dcd7d6c4b798155b9be31cf97ec","IPY_MODEL_af1187adfb8647b1af768b8de27f7ba2"]}},"c7e76e76bfde4b4bb290e4ad44b2cbb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5f0c7dcd7d6c4b798155b9be31cf97ec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_05cb08d83de34d8eb9ddbe5d129284d3","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":760,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":760,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_673eecaab5eb49779f5676d96888d07d"}},"af1187adfb8647b1af768b8de27f7ba2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_78a2f4c1325b43a8b9d4416e83b97901","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 760/760 [00:00&lt;00:00, 1.38kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5fbc697c8d3d448d9ba97877ee3877d6"}},"05cb08d83de34d8eb9ddbe5d129284d3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"673eecaab5eb49779f5676d96888d07d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"78a2f4c1325b43a8b9d4416e83b97901":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5fbc697c8d3d448d9ba97877ee3877d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3b9e75e7c5344edfb4721a671c20576c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_710d35f45e2c445ab7f1e760d5628b40","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f674839f6a8242cb802cf07c72e08b37","IPY_MODEL_a0c73b59a2da4820b8274dd960b823cb"]}},"710d35f45e2c445ab7f1e760d5628b40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f674839f6a8242cb802cf07c72e08b37":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f8e9f2022613426791c568b2fc0ce3b8","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":467042463,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":467042463,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9fbe8f71d2564e6cb9101403f348e2ba"}},"a0c73b59a2da4820b8274dd960b823cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9b4e47dafa3b47678d17c5c74990a5d0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 467M/467M [00:11&lt;00:00, 42.4MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_baa40ff065d94281b00e940bd3cd73c9"}},"f8e9f2022613426791c568b2fc0ce3b8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9fbe8f71d2564e6cb9101403f348e2ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9b4e47dafa3b47678d17c5c74990a5d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"baa40ff065d94281b00e940bd3cd73c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6f0d663f1a504f9e95220f56a927b520":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c152292da64f4d51a4c2f71fb89fab22","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ed9785d20c914e4bba1886bd9e11c0cb","IPY_MODEL_b3b034f2e77a46eba7fef02152f77a6b"]}},"c152292da64f4d51a4c2f71fb89fab22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ed9785d20c914e4bba1886bd9e11c0cb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ce98ba8b43fe42e993ba0295384044af","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":100441675,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":100441675,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7f1fb95819584e1696a46d84f542b9a7"}},"b3b034f2e77a46eba7fef02152f77a6b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9315e14bc48448eaa029be0d074e6917","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 95.8M/95.8M [00:39&lt;00:00, 2.54MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_be498b5d7fa541c08be27d0e0a25cbcd"}},"ce98ba8b43fe42e993ba0295384044af":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7f1fb95819584e1696a46d84f542b9a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9315e14bc48448eaa029be0d074e6917":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"be498b5d7fa541c08be27d0e0a25cbcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qc_rI6d-khY2","outputId":"2b2c4fa0-40cd-4be5-f369-e668226b153d"},"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QzejvNI6kk3A"},"source":["!pip3 install torch torchvision pandas transformers scikit-learn tensorflow numpy seaborn matplotlib textwrap3 sentencepiece"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zrBErHTyknRL","outputId":"ab811404-8c07-4344-84d5-39b49f8c6de2"},"source":["import torch\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"c9plONFGko6I"},"source":["import transformers\n","from transformers import XLNetModel, XLNetTokenizer, XLNetForSequenceClassification, BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n","import torch\n","from torchvision import transforms\n","import torchvision\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import re\n","from matplotlib import rc\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, classification_report\n","from collections import defaultdict\n","from textwrap import wrap\n","from torch import nn, optim\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","\n","PRE_TRAINED_MODEL_NAME = 'xlnet-base-cased'\n","\n","def clean_text(text):\n","    text = re.sub(r\"@[A-Za-z0-9_]+\", ' ', text)\n","    text = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', text)\n","    text = re.sub(r\"[^a-zA-z.,!?'0-9]\", ' ', text)\n","    text = re.sub('\\t', ' ',  text)\n","    text = re.sub(r\" +\", ' ', text)\n","    return text\n","\n","def label_to_target(text):\n","  if text == \"informative\":\n","    return 1\n","  else:\n","    return 0\n","\n","df_train = pd.read_csv(\"./gdrive/MyDrive/FYP/task_informative_text_img_agreed_lab_train.tsv\", sep='\\t')\n","df_train = df_train[['image', 'tweet_text', 'label_text']]\n","df_train = df_train.sample(frac=1, random_state = 24).reset_index(drop=True)\n","df_train['tweet_text'] = df_train['tweet_text'].apply(clean_text)\n","df_train['label_text'] = df_train['label_text'].apply(label_to_target)\n","\n","df_val = pd.read_csv(\"./gdrive/MyDrive/FYP/task_informative_text_img_agreed_lab_dev.tsv\", sep='\\t')\n","df_val = df_val[['image', 'tweet_text', 'label_text']]\n","df_val = df_val.sample(frac=1, random_state = 24).reset_index(drop=True)\n","df_val['tweet_text'] = df_val['tweet_text'].apply(clean_text)\n","df_val['label_text'] = df_val['label_text'].apply(label_to_target)\n","\n","df_test = pd.read_csv(\"./gdrive/MyDrive/FYP/task_informative_text_img_agreed_lab_test.tsv\", sep='\\t')\n","df_test = df_test[['image', 'tweet_text', 'label_text']]\n","df_test = df_test.sample(frac=1, random_state = 24).reset_index(drop=True)\n","df_test['tweet_text'] = df_test['tweet_text'].apply(clean_text)\n","df_test['label_text'] = df_test['label_text'].apply(label_to_target)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YOjM9tz8ksnJ"},"source":["data_dir = \"./gdrive/MyDrive/FYP/\"\n","class DisasterTweetDataset(Dataset):\n","\n","  def __init__(self, tweets, targets, paths, tokenizer, max_len):\n","    self.tweets = tweets\n","    self.targets = targets\n","    self.tokenizer = tokenizer\n","    self.max_len = max_len\n","    self.paths = paths\n","    self.transform = transforms.Compose([\n","        transforms.Resize(size=256),\n","        transforms.CenterCrop(size=224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ])\n","  \n","  def __len__(self):\n","    return len(self.tweets)\n","  \n","  def __getitem__(self, item):\n","    tweet = str(self.tweets[item])\n","    target = self.targets[item]\n","    path = str(self.paths[item])\n","    img = Image.open(data_dir+self.paths[item]).convert('RGB')\n","    img = self.transform(img)  \n","\n","    encoding = self.tokenizer.encode_plus(\n","      tweet,\n","      add_special_tokens=True,\n","      max_length=self.max_len,\n","      return_token_type_ids=False,\n","      padding='max_length',\n","      return_attention_mask=True,\n","      return_tensors='pt',\n","      truncation = True\n","    )\n","\n","    return {\n","      'tweet_text': tweet,\n","      'input_ids': encoding['input_ids'].flatten(),\n","      'attention_mask': encoding['attention_mask'].flatten(),\n","      'targets': torch.tensor(target, dtype=torch.long),\n","      'tweet_image': img\n","    }\n","\n","def create_data_loader(df, tokenizer, max_len, batch_size):\n","  ds = DisasterTweetDataset(\n","    tweets=df.tweet_text.to_numpy(),\n","    targets=df.label_text.to_numpy(),\n","    paths=df.image.to_numpy(),\n","    tokenizer=tokenizer,\n","    max_len=max_len\n","  )\n","\n","  return DataLoader(\n","    ds,\n","    batch_size=batch_size,\n","    num_workers=2\n","  )\n","\n","\n","class TweetClassifier(nn.Module):\n","\n","  def __init__(self):\n","    super(TweetClassifier, self).__init__()\n","    self.bert = XLNetModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n","    for param in self.bert.parameters():\n","      param.requires_grad = False\n","    \n","    self.resnet = torchvision.models.resnext50_32x4d(pretrained=True)\n","    for param in self.resnet.parameters():\n","      param.requires_grad = False\n","    \n","    self.bn = nn.BatchNorm1d(self.bert.config.hidden_size + 1000)\n","\n","    self.linear1 = nn.Linear(self.bert.config.hidden_size + 1000, 1000)\n","    self.relu1    = nn.ReLU()\n","    self.dropout1 = nn.Dropout(p=0.4)\n","\n","    self.linear2 = nn.Linear(1000, 500)\n","    self.relu2    = nn.ReLU()\n","    self.dropout2 = nn.Dropout(p=0.2)\n","\n","    self.linear3 = nn.Linear(500, 250)\n","    self.relu3    = nn.ReLU()\n","    self.dropout3 = nn.Dropout(p=0.1)\n","\n","    self.linear4 = nn.Linear(250, 125)\n","    self.relu4    = nn.ReLU()\n","    self.dropout4 = nn.Dropout(p=0.02)\n","\n","    self.linear5 = nn.Linear(125, 1)\n","    self.sigmoid = nn.Sigmoid()\n","  \n","  def forward(self, input_ids, attention_mask, tweet_img):\n","    text_output = self.bert(\n","      input_ids=input_ids,\n","      attention_mask=attention_mask,\n","      return_dict=False\n","    )\n","    image_output = self.resnet(tweet_img)\n","    merged_output = torch.cat((torch.mean(text_output[0], 1), image_output), dim=1)\n","    bn_output = self.bn(merged_output)\n","\n","    linear1_output = self.linear1(bn_output)\n","    relu1_output = self.relu1(linear1_output)\n","    dropout1_output = self.dropout1(relu1_output)\n","\n","    linear2_output = self.linear2(dropout1_output)\n","    relu2_output = self.relu2(linear2_output)\n","    dropout2_output = self.dropout2(relu2_output)\n","\n","    linear3_output = self.linear3(dropout2_output)\n","    relu3_output = self.relu3(linear3_output)\n","    dropout3_output = self.dropout3(relu3_output)\n","\n","    linear4_output = self.linear4(dropout3_output)\n","    relu4_output = self.relu4(linear4_output)\n","    dropout4_output = self.dropout4(relu4_output)\n","\n","    linear5_output = self.linear5(dropout4_output)\n","\n","\n","    probas = self.sigmoid(linear5_output)\n","    return probas\n","\n","\n","def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n","  model = model.train()\n","\n","  losses = []\n","  correct_predictions = 0\n","  \n","  for d in data_loader:\n","    tweet_imgs = d[\"tweet_image\"].to(device)\n","    input_ids = d[\"input_ids\"].to(device)\n","    attention_mask = d[\"attention_mask\"].to(device)\n","    targets = d[\"targets\"].reshape(-1, 1).float()\n","    targets = targets.to(device)\n","\n","    outputs = model(\n","      input_ids=input_ids,\n","      attention_mask=attention_mask,\n","      tweet_img = tweet_imgs\n","    )\n","\n","\n","    loss = loss_fn(outputs, targets)\n","\n","    correct_predictions += torch.sum(torch.round(outputs) == targets)\n","    losses.append(loss.item())\n","\n","    loss.backward()\n","    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","    optimizer.step()\n","    scheduler.step()\n","    optimizer.zero_grad()\n","\n","  return correct_predictions.double() / n_examples, np.mean(losses)\n","\n","def eval_model(model, data_loader, loss_fn, device, n_examples):\n","  model = model.eval()\n","\n","  losses = []\n","  correct_predictions = 0\n","\n","  with torch.no_grad():\n","    for d in data_loader:\n","      tweet_imgs = d[\"tweet_image\"].to(device)\n","      input_ids = d[\"input_ids\"].to(device)\n","      attention_mask = d[\"attention_mask\"].to(device)\n","      targets = d[\"targets\"].reshape(-1, 1).float()\n","      targets = targets.to(device)\n","\n","      outputs = model(\n","        input_ids=input_ids,\n","        attention_mask=attention_mask,\n","        tweet_img = tweet_imgs\n","      )\n","\n","      loss = loss_fn(outputs, targets)\n","\n","      correct_predictions += torch.sum(torch.round(outputs) == targets)\n","      losses.append(loss.item())\n","\n","  return correct_predictions.double() / n_examples, np.mean(losses)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cP2k2wgLkyo2","colab":{"base_uri":"https://localhost:8080/","height":279,"referenced_widgets":["149ec9649d3640729f927cd8b2e7f8ae","a4fbbae186f846df907c6a200b6dcae2","25ad982f015844cd9cc97d406b3493b5","b8ce4b78d5984915bf6409bea2b96401","5dd76a394a384d41ac7bacb410513b44","d26ec7e15f4e4ba5805f754e1d6e9b62","e6ef0e175aa64da48c8d0c5ef73c1876","4a4c69b3a177490da45a8c4d0d4c4b6c","03c58a1b5c9944cd9233b2365693b83c","05d29521c6624f1b9cc5e826fbbe2fbd","ed91a558915b424f8ff9a824479b8d1b","f501f0cee75b43ac89759f09a43f8799","d08e9fb278324b25ae052c1bd5e07f33","12588739dc044ea5adc790589f0fa6b9","df03682c782c49cf88217f08273963f4","9e34216ef18f40bf88c1f6e8fa790dfb","fb1413e27a02414fb8cf45f10c995964","c7e76e76bfde4b4bb290e4ad44b2cbb3","5f0c7dcd7d6c4b798155b9be31cf97ec","af1187adfb8647b1af768b8de27f7ba2","05cb08d83de34d8eb9ddbe5d129284d3","673eecaab5eb49779f5676d96888d07d","78a2f4c1325b43a8b9d4416e83b97901","5fbc697c8d3d448d9ba97877ee3877d6","3b9e75e7c5344edfb4721a671c20576c","710d35f45e2c445ab7f1e760d5628b40","f674839f6a8242cb802cf07c72e08b37","a0c73b59a2da4820b8274dd960b823cb","f8e9f2022613426791c568b2fc0ce3b8","9fbe8f71d2564e6cb9101403f348e2ba","9b4e47dafa3b47678d17c5c74990a5d0","baa40ff065d94281b00e940bd3cd73c9","6f0d663f1a504f9e95220f56a927b520","c152292da64f4d51a4c2f71fb89fab22","ed9785d20c914e4bba1886bd9e11c0cb","b3b034f2e77a46eba7fef02152f77a6b","ce98ba8b43fe42e993ba0295384044af","7f1fb95819584e1696a46d84f542b9a7","9315e14bc48448eaa029be0d074e6917","be498b5d7fa541c08be27d0e0a25cbcd"]},"outputId":"7acffe03-8dc2-4bbe-e82c-b7fd8595afc5"},"source":["BATCH_SIZE = 512\n","MAX_LEN = 150\n","\n","tokenizer = XLNetTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n","\n","train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n","val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n","test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)\n","\n","\n","model = TweetClassifier()\n","model = model.to(device)\n","\n","EPOCHS = 50\n","\n","optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n","total_steps = len(train_data_loader) * EPOCHS\n","\n","scheduler = get_linear_schedule_with_warmup(\n","  optimizer,\n","  num_warmup_steps=0,\n","  num_training_steps=total_steps\n",")\n","\n","loss_fn = nn.BCELoss().to(device)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"149ec9649d3640729f927cd8b2e7f8ae","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=798011.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"03c58a1b5c9944cd9233b2365693b83c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1382015.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fb1413e27a02414fb8cf45f10c995964","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b9e75e7c5344edfb4721a671c20576c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=467042463.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /root/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6f0d663f1a504f9e95220f56a927b520","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=100441675.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v-eqL1yqUP5a","outputId":"a5494bb9-9d9b-4efd-9502-c68c77eeb223"},"source":["checkpoint = torch.load(\"./gdrive/MyDrive/FYP/XlnetResNeXt-checkpoint.t7\",map_location=torch.device('cpu'))\n","model.load_state_dict(checkpoint['state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer'])\n","start_epoch = checkpoint['epoch']\n","best_accuracy = checkpoint['best_accuracy']\n","\n","print(start_epoch)\n","print(best_accuracy)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["29\n","tensor(0.8468, dtype=torch.float64)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CK6j-pnDk1d6","outputId":"fcdb4360-1cc7-4c47-b770-18f12d527483"},"source":["history = defaultdict(list)\n","start_epoch = 0\n","best_accuracy = -1\n","\n","# checkpoint = torch.load(\"./gdrive/MyDrive/FYP/BertResNet-checkpoint.t7\")\n","# model.load_state_dict(checkpoint['state_dict'])\n","# optimizer.load_state_dict(checkpoint['optimizer'])\n","# start_epoch = checkpoint['epoch']\n","# best_accuracy = checkpoint['best_accuracy']\n","# print(start_epoch)\n","# print(best_accuracy)\n","\n","\n","for epoch in range(EPOCHS):\n","\n","  print(f'Epoch {start_epoch + epoch + 1}/{start_epoch + EPOCHS}')\n","  print('-' * 10)\n","\n","  train_acc, train_loss = train_epoch(\n","    model,\n","    train_data_loader,    \n","    loss_fn, \n","    optimizer, \n","    device, \n","    scheduler, \n","    len(df_train)\n","  )\n","\n","  print(f'Train loss {train_loss} accuracy {train_acc}')\n","\n","  val_acc, val_loss = eval_model(\n","    model,\n","    val_data_loader,\n","    loss_fn, \n","    device, \n","    len(df_val)\n","  )\n","\n","  print(f'Val   loss {val_loss} accuracy {val_acc}')\n","  print()\n","\n","  history['train_acc'].append(train_acc)\n","  history['train_loss'].append(train_loss)\n","  history['val_acc'].append(val_acc)\n","  history['val_loss'].append(val_loss)\n","\n","  if val_acc > best_accuracy:\n","    state = {\n","            'best_accuracy': val_acc,\n","            'epoch': start_epoch+epoch+1,\n","            'state_dict': model.state_dict(),\n","            'optimizer': optimizer.state_dict(),\n","    }\n","    savepath= \"./gdrive/MyDrive/FYP/XlnetResNeXt-checkpoint.t7\"\n","    torch.save(state,savepath)\n","    best_accuracy = val_acc"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.6174275216303373 accuracy 0.6608686595146339\n","Val   loss 0.517289012670517 accuracy 0.6713286713286714\n","\n","Epoch 2/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.48985101988441065 accuracy 0.7508592854910947\n","Val   loss 0.45694825053215027 accuracy 0.7997457088366179\n","\n","Epoch 3/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.4000147879123688 accuracy 0.8376210811373815\n","Val   loss 0.4223952442407608 accuracy 0.8111888111888113\n","\n","Epoch 4/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.3454629245557283 accuracy 0.8524112071659202\n","Val   loss 0.43520487844944 accuracy 0.813731722822632\n","\n","Epoch 5/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.32566360737148087 accuracy 0.8619935423393397\n","Val   loss 0.4344615116715431 accuracy 0.8181818181818182\n","\n","Epoch 6/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.3078166779718901 accuracy 0.8706384751588376\n","Val   loss 0.4300250932574272 accuracy 0.8207247298156389\n","\n","Epoch 7/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.30514628949918243 accuracy 0.8724091240495782\n","Val   loss 0.42493997514247894 accuracy 0.82453909726637\n","\n","Epoch 8/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.28989928098101364 accuracy 0.8801166545151546\n","Val   loss 0.41851554811000824 accuracy 0.8270820089001907\n","\n","Epoch 9/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.28818509139512716 accuracy 0.8799083428809499\n","Val   loss 0.4030940309166908 accuracy 0.8340750158931978\n","\n","Epoch 10/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.2788267057192953 accuracy 0.8838662639308406\n","Val   loss 0.4039871469140053 accuracy 0.8366179275270185\n","\n","Epoch 11/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.273712138596334 accuracy 0.8877200291636288\n","Val   loss 0.4007994383573532 accuracy 0.8404322949777495\n","\n","Epoch 12/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.2706366722521029 accuracy 0.8879283407978336\n","Val   loss 0.39104317873716354 accuracy 0.8417037507946599\n","\n","Epoch 13/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.26873414453707245 accuracy 0.8918862618477241\n","Val   loss 0.3878622129559517 accuracy 0.8410680228862047\n","\n","Epoch 14/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.2603033561455576 accuracy 0.8965732736173315\n","Val   loss 0.38385408371686935 accuracy 0.8417037507946599\n","\n","Epoch 15/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.25514320950759084 accuracy 0.8928236642016456\n","Val   loss 0.39359813928604126 accuracy 0.8404322949777495\n","\n","Epoch 16/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.258559461486967 accuracy 0.892927820018748\n","Val   loss 0.3819297105073929 accuracy 0.8436109345200254\n","\n","Epoch 17/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.25161077474292953 accuracy 0.8941776898239766\n","Val   loss 0.37787624448537827 accuracy 0.8436109345200254\n","\n","Epoch 18/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.24603986347976484 accuracy 0.9001145713988126\n","Val   loss 0.3782297596335411 accuracy 0.8429752066115702\n","\n","Epoch 19/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.2439024330754029 accuracy 0.9011561295698365\n","Val   loss 0.3856223523616791 accuracy 0.8410680228862047\n","\n","Epoch 20/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.2446115338488629 accuracy 0.8987605457764816\n","Val   loss 0.3860945850610733 accuracy 0.8429752066115702\n","\n","Epoch 21/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.24021799313394646 accuracy 0.904280804082908\n","Val   loss 0.3908577337861061 accuracy 0.8404322949777495\n","\n","Epoch 22/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.23651834381254097 accuracy 0.9032392459118842\n","Val   loss 0.3891975060105324 accuracy 0.8423394787031151\n","\n","Epoch 23/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.24083683286842547 accuracy 0.8991771690448911\n","Val   loss 0.39008256047964096 accuracy 0.8417037507946599\n","\n","Epoch 24/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.235783955768535 accuracy 0.9033434017289865\n","Val   loss 0.3904232680797577 accuracy 0.8423394787031151\n","\n","Epoch 25/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.22973058098240903 accuracy 0.9089678158525153\n","Val   loss 0.38608764857053757 accuracy 0.8429752066115702\n","\n","Epoch 26/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.22767365135644613 accuracy 0.9065722320591605\n","Val   loss 0.39156804233789444 accuracy 0.8410680228862047\n","\n","Epoch 27/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.235876852744504 accuracy 0.902093531923758\n","Val   loss 0.38576650619506836 accuracy 0.8461538461538461\n","\n","Epoch 28/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.2274542411691264 accuracy 0.909696906572232\n","Val   loss 0.389716699719429 accuracy 0.8448823903369358\n","\n","Epoch 29/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.22330063267758019 accuracy 0.9093844391209249\n","Val   loss 0.3876388445496559 accuracy 0.8467895740623014\n","\n","Epoch 30/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.2250657630594153 accuracy 0.9080304134985938\n","Val   loss 0.3931454047560692 accuracy 0.8442466624284807\n","\n","Epoch 31/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.22207061475829074 accuracy 0.9089678158525153\n","Val   loss 0.39090824872255325 accuracy 0.8442466624284807\n","\n","Epoch 32/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.22293542325496674 accuracy 0.9098010623893344\n","Val   loss 0.39399299025535583 accuracy 0.8429752066115702\n","\n","Epoch 33/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.22351814963315664 accuracy 0.9114675554629725\n","Val   loss 0.38968174159526825 accuracy 0.8442466624284807\n","\n","Epoch 34/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.21733566491227402 accuracy 0.9123008019997917\n","Val   loss 0.39499572664499283 accuracy 0.8423394787031151\n","\n","Epoch 35/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.21455484314968712 accuracy 0.9163628788667847\n","Val   loss 0.3885865956544876 accuracy 0.845518118245391\n","\n","Epoch 36/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.2164141661242435 accuracy 0.9160504114154775\n","Val   loss 0.39121294766664505 accuracy 0.8448823903369358\n","\n","Epoch 37/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.2132737111104162 accuracy 0.9170919695865014\n","Val   loss 0.39342670887708664 accuracy 0.845518118245391\n","\n","Epoch 38/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.21886407466311203 accuracy 0.910530153109051\n","Val   loss 0.38754069805145264 accuracy 0.8448823903369358\n","\n","Epoch 39/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.21583695788132518 accuracy 0.9118841787313822\n","Val   loss 0.3874114528298378 accuracy 0.8448823903369358\n","\n","Epoch 40/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.21481207091557353 accuracy 0.9130298927195084\n","Val   loss 0.3874918892979622 accuracy 0.8429752066115702\n","\n","Epoch 41/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.2137193240617451 accuracy 0.9131340485366107\n","Val   loss 0.3841201290488243 accuracy 0.8442466624284807\n","\n","Epoch 42/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.20859976191269725 accuracy 0.9159462555983752\n","Val   loss 0.3847603350877762 accuracy 0.8442466624284807\n","\n","Epoch 43/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.2116543627098987 accuracy 0.9165711905009895\n","Val   loss 0.3853360116481781 accuracy 0.8448823903369358\n","\n","Epoch 44/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.21136495157292015 accuracy 0.915633788147068\n","Val   loss 0.3850027024745941 accuracy 0.845518118245391\n","\n","Epoch 45/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.209483487041373 accuracy 0.9174044370378085\n","Val   loss 0.3859716057777405 accuracy 0.845518118245391\n","\n","Epoch 46/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.20749654816953758 accuracy 0.9163628788667847\n","Val   loss 0.3874707594513893 accuracy 0.845518118245391\n","\n","Epoch 47/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.20998692747793699 accuracy 0.9166753463180919\n","Val   loss 0.38749896734952927 accuracy 0.8461538461538461\n","\n","Epoch 48/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 0.21037562113059194 accuracy 0.9159462555983752\n","Val   loss 0.38627149909734726 accuracy 0.845518118245391\n","\n","Epoch 49/50\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"CGFmTSaxYMw-"},"source":["state = {\n","        'epoch': start_epoch + EPOCHS,\n","        'state_dict': model.state_dict(),\n","        'optimizer': optimizer.state_dict(),\n","}\n","savepath= \"./gdrive/MyDrive/FYP/XlnetResNeXt-checkpoint-{}.t7\".format(start_epoch + EPOCHS)\n","torch.save(state,savepath)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ScOj15BovCww","colab":{"base_uri":"https://localhost:8080/","height":231},"outputId":"e274faf3-95a8-46af-af26-b0e1aa0291a0"},"source":["plt.plot(history['train_acc'], label='train accuracy')\n","plt.plot(history['val_acc'], label='validation accuracy')\n","\n","plt.title('Training history')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend()\n","plt.ylim([0, 1]);"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-0d8ecf63c1ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'validation accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training history'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"]}]},{"cell_type":"code","metadata":{"id":"pTghsXN8vEpo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8a41b81c-083b-42d4-eceb-9443bdbba76a"},"source":["def get_predictions(model, data_loader):\n","  model = model.eval()\n","  \n","  predictions = []\n","  real_values = []\n","\n","  with torch.no_grad():\n","    for d in data_loader:\n","\n","      input_ids = d[\"input_ids\"].to(device)\n","      tweet_imgs = d[\"tweet_image\"].to(device)\n","      attention_mask = d[\"attention_mask\"].to(device)\n","      targets = d[\"targets\"].reshape(-1, 1).float()\n","      targets = targets.to(device)\n","\n","      outputs = model(\n","        input_ids=input_ids,\n","        attention_mask=attention_mask,\n","        tweet_img = tweet_imgs\n","      )\n","      preds = torch.round(outputs)\n","\n","\n","      predictions.extend(preds)\n","      real_values.extend(targets)\n","\n","  predictions = torch.stack(predictions).cpu()\n","  real_values = torch.stack(real_values).cpu()\n","  return predictions, real_values\n","\n","y_pred, y_test = get_predictions(\n","  model,\n","  test_data_loader\n",")\n","\n","print(classification_report(y_test, y_pred, target_names=['Not Informative', 'Informative'], digits=4))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["                 precision    recall  f1-score   support\n","\n","Not Informative     0.8864    0.6349    0.7399       504\n","    Informative     0.8431    0.9602    0.8979      1030\n","\n","       accuracy                         0.8533      1534\n","      macro avg     0.8648    0.7976    0.8189      1534\n","   weighted avg     0.8574    0.8533    0.8460      1534\n","\n"],"name":"stdout"}]}]}