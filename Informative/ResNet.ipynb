{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc_rI6d-khY2",
        "outputId": "b32a022c-1ee0-4c13-bdc5-449ff33c9eb9"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzejvNI6kk3A"
      },
      "source": [
        "!pip3 install torch torchvision pandas transformers scikit-learn tensorflow numpy seaborn matplotlib textwrap3 sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwWQL0acqLuH",
        "outputId": "73a14d43-30df-4e4e-894e-60a0bec3d1c8"
      },
      "source": [
        "!ls gdrive/MyDrive/data_image"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "california_wildfires  hurricane_irma   iraq_iran_earthquake  srilanka_floods\n",
            "hurricane_harvey      hurricane_maria  mexico_earthquake\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrBErHTyknRL",
        "outputId": "42fbc569-ad46-4a22-b2e1-0c0fcc2a7c4a"
      },
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9plONFGko6I"
      },
      "source": [
        "import transformers\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r\"@[A-Za-z0-9_]+\", ' ', text)\n",
        "    text = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', text)\n",
        "    text = re.sub(r\"[^a-zA-z.,!?'0-9]\", ' ', text)\n",
        "    text = re.sub('\\t', ' ',  text)\n",
        "    text = re.sub(r\" +\", ' ', text)\n",
        "    return text\n",
        "\n",
        "def label_to_target(text):\n",
        "  if text == \"informative\":\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "df_train = pd.read_csv(\"./gdrive/MyDrive/Models/train.tsv\", sep='\\t')\n",
        "df_train = df_train[['image', 'label_text']]\n",
        "df_train = df_train.sample(frac=1, random_state = 24).reset_index(drop=True)\n",
        "df_train['label_text'] = df_train['label_text'].apply(label_to_target)\n",
        "\n",
        "df_val = pd.read_csv(\"./gdrive/MyDrive/Models/val.tsv\", sep='\\t')\n",
        "df_val = df_val[['image', 'label_text']]\n",
        "df_val = df_val.sample(frac=1, random_state = 24).reset_index(drop=True)\n",
        "df_val['label_text'] = df_val['label_text'].apply(label_to_target)\n",
        "\n",
        "df_test = pd.read_csv(\"./gdrive/MyDrive/Models/test.tsv\", sep='\\t')\n",
        "df_test = df_test[['image', 'label_text']]\n",
        "df_test = df_test.sample(frac=1, random_state = 24).reset_index(drop=True)\n",
        "df_test['label_text'] = df_test['label_text'].apply(label_to_target)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOjM9tz8ksnJ"
      },
      "source": [
        "data_dir = \"./gdrive/MyDrive/\"\n",
        "class DisasterTweetDataset(Dataset):\n",
        "\n",
        "  def __init__(self, paths, targets):\n",
        "    self.paths = paths\n",
        "    self.targets = targets\n",
        "    self.transform = transforms.Compose([\n",
        "        transforms.Resize(size=256),\n",
        "        transforms.CenterCrop(size=224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.paths)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    path = str(self.paths[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    img = Image.open(data_dir+self.paths[item]).convert('RGB')\n",
        "    img = self.transform(img)  \n",
        "\n",
        "    return {\n",
        "      'tweet_image': img,\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }\n",
        "\n",
        "def create_data_loader(df, batch_size):\n",
        "  ds = DisasterTweetDataset(\n",
        "    paths=df.image.to_numpy(),\n",
        "    targets=df.label_text.to_numpy(),\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=2\n",
        "  )\n",
        "\n",
        "\n",
        "class TweetClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(TweetClassifier, self).__init__()\n",
        "    self.resnet = torchvision.models.resnet18(pretrained=True)\n",
        "    # for param in self.resnet.parameters():\n",
        "    #   param.requires_grad = False\n",
        "\n",
        "    self.linear1 = nn.Linear(1000, 256)\n",
        "    self.relu    = nn.ReLU()\n",
        "    self.dropout = nn.Dropout(p=0.4)\n",
        "    self.linear2 = nn.Linear(256, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "  \n",
        "  def forward(self, tweet_img):\n",
        "    output = self.resnet(tweet_img)\n",
        "    linear1_output = self.linear1(output)\n",
        "    relu_output = self.relu(linear1_output)\n",
        "    dropout_output = self.dropout(relu_output)\n",
        "    linear2_output = self.linear2(dropout_output)\n",
        "    probas = self.sigmoid(linear2_output)\n",
        "    return probas\n",
        "\n",
        "\n",
        "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  \n",
        "  for d in data_loader:\n",
        "    tweet_imgs = d[\"tweet_image\"].to(device)\n",
        "    targets = d[\"targets\"].reshape(-1, 1).float()\n",
        "    targets = targets.to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      tweet_img = tweet_imgs\n",
        "    )\n",
        "\n",
        "\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(torch.round(outputs) == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)\n",
        "\n",
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      tweet_imgs = d[\"tweet_image\"].to(device)\n",
        "      targets = d[\"targets\"].reshape(-1, 1).float()\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        tweet_img = tweet_imgs\n",
        "      )\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(torch.round(outputs) == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP2k2wgLkyo2"
      },
      "source": [
        "BATCH_SIZE = 512\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, BATCH_SIZE)\n",
        "\n",
        "\n",
        "model = TweetClassifier()\n",
        "model = model.to(device)\n",
        "\n",
        "EPOCHS = 40\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.BCELoss().to(device)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CK6j-pnDk1d6",
        "outputId": "b0b2c9e4-d26d-4034-dec1-a6fc3d37a60c"
      },
      "source": [
        "history = defaultdict(list)\n",
        "start_epoch = 0\n",
        "best_accuracy = -1\n",
        "\n",
        "checkpoint = torch.load(\"./gdrive/MyDrive/Models/ResNet/checkpoint.t7\")\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "start_epoch = checkpoint['epoch']\n",
        "\n",
        "print(start_epoch)\n",
        "\n",
        "\n",
        "# for epoch in range(EPOCHS):\n",
        "\n",
        "#   print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "#   print('-' * 10)\n",
        "\n",
        "#   train_acc, train_loss = train_epoch(\n",
        "#     model,\n",
        "#     train_data_loader,    \n",
        "#     loss_fn, \n",
        "#     optimizer, \n",
        "#     device, \n",
        "#     scheduler, \n",
        "#     len(df_train)\n",
        "#   )\n",
        "\n",
        "#   print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "#   val_acc, val_loss = eval_model(\n",
        "#     model,\n",
        "#     val_data_loader,\n",
        "#     loss_fn, \n",
        "#     device, \n",
        "#     len(df_val)\n",
        "#   )\n",
        "\n",
        "#   print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "#   print()\n",
        "\n",
        "#   history['train_acc'].append(train_acc)\n",
        "#   history['train_loss'].append(train_loss)\n",
        "#   history['val_acc'].append(val_acc)\n",
        "#   history['val_loss'].append(val_loss)\n",
        "\n",
        "#   if val_acc > best_accuracy:\n",
        "#     state = {\n",
        "#             'best_accuracy': val_acc,\n",
        "#             'epoch': start_epoch+epoch+1,\n",
        "#             'state_dict': model.state_dict(),\n",
        "#             'optimizer': optimizer.state_dict(),\n",
        "#     }\n",
        "#     savepath= \"./gdrive/MyDrive/Models/ResNet/checkpoint.t7\"\n",
        "#     torch.save(state,savepath)\n",
        "#     best_accuracy = val_acc"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Taz58ppcm8n8"
      },
      "source": [
        "state = {\n",
        "        'epoch': start_epoch + EPOCHS,\n",
        "        'state_dict': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "}\n",
        "savepath= \"./gdrive/MyDrive/Models/ResNet/checkpoint-{}.t7\".format(start_epoch + EPOCHS)\n",
        "torch.save(state,savepath)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ScOj15BovCww",
        "outputId": "09c9aef6-e8eb-48bf-a4f8-5b1c751d7a0d"
      },
      "source": [
        "plt.plot(history['train_acc'], label='train accuracy')\n",
        "plt.plot(history['val_acc'], label='validation accuracy')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTghsXN8vEpo",
        "outputId": "4c8db12f-51fc-42dd-cd4d-8e956bef45cf"
      },
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  \n",
        "  predictions = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      tweet_imgs = d[\"tweet_image\"].to(device)\n",
        "      targets = d[\"targets\"].reshape(-1, 1).float()\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      outputs = model(tweet_img=tweet_imgs)\n",
        "      preds = torch.round(outputs)\n",
        "\n",
        "\n",
        "      predictions.extend(preds)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return predictions, real_values\n",
        "\n",
        "y_pred, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=['Not Informative', 'Informative']))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Not Informative       0.78      0.75      0.77       504\n",
            "    Informative       0.88      0.90      0.89      1030\n",
            "\n",
            "       accuracy                           0.85      1534\n",
            "      macro avg       0.83      0.82      0.83      1534\n",
            "   weighted avg       0.85      0.85      0.85      1534\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}