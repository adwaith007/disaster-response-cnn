{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KimCNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkYOJmxmJ2pQ",
        "outputId": "6f370249-9f1e-4cb6-e4aa-63b83768cbae"
      },
      "source": [
        "from google.colab import drive\n",
        " \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVfbg6pWv7o_"
      },
      "source": [
        "!pip3 install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36GiLe3tUEw7",
        "outputId": "8741fea4-b0bb-4159-f004-a1053e6e424b"
      },
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wwc4P3iJ-C0"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "import re \n",
        "import numpy as np \n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torchvision import models\n",
        "from sklearn.metrics import classification_report\n",
        "from collections import Counter\n",
        "from collections import defaultdict\n",
        "from gensim.models import KeyedVectors"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKue_-UPEyQV"
      },
      "source": [
        "def label_to_target(text):\n",
        "  if text == \"not_humanitarian\":\n",
        "    return 0\n",
        "  elif text == \"infrastructure_and_utility_damage\":\n",
        "    return 1\n",
        "  elif text == \"other_relevant_information\":\n",
        "    return 2\n",
        "  elif text == \"rescue_volunteering_or_donation_effort\":\n",
        "    return 3\n",
        "  elif text == \"affected_individuals\":\n",
        "    return 4\n",
        "\n",
        "\n",
        "df_train = pd.read_csv(\"./gdrive/MyDrive/Models/train_processed.tsv\", sep='\\t')\n",
        "df_train = df_train[['tweet_text', 'label_text']]\n",
        "df_train = df_train.sample(frac=1, random_state = 24).reset_index(drop=True)\n",
        "df_train['label_text'] = df_train['label_text'].apply(label_to_target)\n",
        "\n",
        "\n",
        "\n",
        "df_val = pd.read_csv(\"./gdrive/MyDrive/Models/val_processed.tsv\", sep='\\t')\n",
        "df_val = df_val[['tweet_text', 'label_text']]\n",
        "df_val = df_val.sample(frac=1, random_state = 24).reset_index(drop=True)\n",
        "df_val['label_text'] = df_val['label_text'].apply(label_to_target)\n",
        "\n",
        "df_test = pd.read_csv(\"./gdrive/MyDrive/Models/test_processed.tsv\", sep='\\t')\n",
        "df_test = df_test[['tweet_text', 'label_text']]\n",
        "df_test = df_test.sample(frac=1, random_state = 24).reset_index(drop=True)\n",
        "df_test['label_text'] = df_test['label_text'].apply(label_to_target)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "568kP1-2E4PC"
      },
      "source": [
        "weights = KeyedVectors.load_word2vec_format('/content/gdrive/MyDrive/crisisNLP_word2vec_model/crisisNLP_word_vector.bin', binary=True)\n",
        "weights = torch.FloatTensor(weights.vectors)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMSghDbajV4b"
      },
      "source": [
        "class DisasterTweetDataset(Dataset):\n",
        "\n",
        "  def __init__(self, tweets, targets):\n",
        "    self.tweets = tweets\n",
        "    self.targets = targets  \n",
        "  def __len__(self):\n",
        "    return len(self.tweets)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    tweet = self.tweets[item]\n",
        "    target = self.targets[item]\n",
        "\n",
        "    tweet = tweet.split(\",\")\n",
        "    tweet = list(map(int, tweet))\n",
        "\n",
        "    return {\n",
        "      'input_ids': torch.tensor(tweet),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }\n",
        "\n",
        "def create_data_loader(df, batch_size):\n",
        "  ds = DisasterTweetDataset(\n",
        "    tweets=df.tweet_text.to_numpy(),\n",
        "    targets=df.label_text.to_numpy()\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=2\n",
        "  )"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkI4V6vvErsc"
      },
      "source": [
        "class kimCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    The embedding layer + CNN model that will be used to perform analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, weights, vocab_size, output_size, embedding_dim, num_filters=100, kernel_sizes=[3, 4, 5], freeze_embeddings=True):\n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers.\n",
        "        \"\"\"\n",
        "        super(kimCNN, self).__init__()\n",
        "\n",
        "        # set class vars\n",
        "        self.num_filters = num_filters\n",
        "        self.embedding_dim = embedding_dim\n",
        "        \n",
        "        self.embedding = nn.Embedding.from_pretrained(weights)\n",
        "        print(self.embedding)\n",
        "        \n",
        "        if freeze_embeddings:\n",
        "            self.embedding.requires_grad = False\n",
        "        \n",
        "        self.x = nn.Conv2d(1,300, (5, embedding_dim))\n",
        "        self.x_relu = nn.ReLU()\n",
        "        self.x_pool = nn.MaxPool2d((MAX_SEQUENCE_LENGTH - 5 + 1, 1))\n",
        "        \n",
        "        self.y = nn.Conv2d(1,300, (4, embedding_dim))\n",
        "        self.y_relu = nn.ReLU()\n",
        "        self.y_pool = nn.MaxPool2d((MAX_SEQUENCE_LENGTH - 4 + 1, 1))\n",
        "\n",
        "\n",
        "        self.z = nn.Conv2d(1,300, (3, embedding_dim))\n",
        "        self.z_relu = nn.ReLU()\n",
        "        self.z_pool = nn.MaxPool2d((MAX_SEQUENCE_LENGTH - 3 + 1, 1))\n",
        "\n",
        "        self.z1 = nn.Conv2d(1,300, (2, embedding_dim))\n",
        "        self.z1_relu = nn.ReLU()\n",
        "        self.z1_pool = nn.MaxPool2d((MAX_SEQUENCE_LENGTH - 2 + 1, 1))\n",
        "\n",
        "        self.w1 = nn.Conv2d(1,300, (1, embedding_dim))\n",
        "        self.w1_relu = nn.ReLU()\n",
        "        self.w1_pool = nn.MaxPool2d((MAX_SEQUENCE_LENGTH - 1 + 1, 1))\n",
        "\n",
        "\n",
        "        self.relu_1 = nn.ReLU()\n",
        "        self.dropout_1 = nn.Dropout(0.02)\n",
        "        self.fc_1 = nn.Linear(1500, 100)\n",
        "        self.relu_2 = nn.ReLU()\n",
        "        self.fc_2 = nn.Linear(100, 50)\n",
        "        self.relu_3 = nn.ReLU()\n",
        "        self.fc_3 = nn.Linear(50, 5)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Defines how a batch of inputs, x, passes through the model layers.\n",
        "        Returns a single, sigmoid-activated class score as output.\n",
        "        \"\"\"\n",
        "\n",
        "        # embedded vectors\n",
        "        embeds1 = self.embedding(x) # (batch_size, seq_length, embedding_dim)\n",
        "        # embeds.unsqueeze(1) creates a channel dimension that conv layers expect\n",
        "        embeds2 = embeds1.unsqueeze(1)\n",
        "\n",
        "        x_out = self.x(embeds2)\n",
        "        x_relu_out = self.x_relu(x_out)\n",
        "        x_pool_out = self.x_pool(x_relu_out)\n",
        "\n",
        "        y_out = self.y(embeds2)\n",
        "        y_relu_out = self.y_relu(y_out)\n",
        "        y_pool_out = self.y_pool(y_relu_out)\n",
        "\n",
        "        z_out = self.z(embeds2)\n",
        "        z_relu_out = self.z_relu(z_out)\n",
        "        z_pool_out = self.z_pool(z_relu_out)\n",
        "\n",
        "        z1_out = self.z1(embeds2)\n",
        "        z1_relu_out = self.z1_relu(z1_out)\n",
        "        z1_pool_out = self.z1_pool(z1_relu_out)\n",
        "\n",
        "        w1_out = self.w1(embeds2)\n",
        "        w1_relu_out = self.w1_relu(w1_out)\n",
        "        w1_pool_out = self.w1_pool(w1_relu_out)\n",
        "\n",
        "        merged_output1 = torch.cat((x_pool_out, y_pool_out, z_pool_out, z1_pool_out, w1_pool_out), dim=1)\n",
        "        merged_output2 = torch.squeeze(merged_output1,3)\n",
        "        merged_output3 = torch.squeeze(merged_output2,2)\n",
        "        #print(merged_output.size())\n",
        "\n",
        "        relu1_out = self.relu_1(merged_output3)\n",
        "\n",
        "        dropout1_out = self.dropout_1(relu1_out)\n",
        "        fc1_out = self.fc_1(dropout1_out)\n",
        "        \n",
        "        relu2_out = self.relu_2(fc1_out)\n",
        "        fc2_out = self.fc_2(relu2_out)\n",
        "\n",
        "        relu3_out = self.relu_3(fc2_out)\n",
        "        fc3_out = self.fc_3(relu3_out)\n",
        "\n",
        "        probas = self.softmax(fc3_out)\n",
        "\n",
        "        return probas\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iU_85zYGR_DU",
        "outputId": "5b4c168d-83d0-4c37-c982-2b64f3f84427"
      },
      "source": [
        "# Instantiate the model w/ hyperparams\n",
        "\n",
        "vocab_size = 2152854 #len(pretrained_words)\n",
        "output_size = 1 # binary class (1 or 0)\n",
        "embedding_dim = 300 #len(embed_lookup[pretrained_words[0]])\n",
        "num_filters = 512\n",
        "kernel_sizes = [2, 3, 4]\n",
        "MAX_SEQUENCE_LENGTH = 25\n",
        "\n",
        "batch_size = 128\n",
        "EPOCHS = 300\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, batch_size)\n",
        "val_data_loader = create_data_loader(df_val, batch_size)\n",
        "test_data_loader = create_data_loader(df_test, batch_size)\n",
        "\n",
        "model = kimCNN(weights, vocab_size, output_size, embedding_dim, num_filters, kernel_sizes)\n",
        "model = model.to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=0.00001)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.00001, betas=(0.9, 0.999))\n",
        "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=10, min_lr=0, verbose=False)\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Embedding(2152854, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOxVqO83GQ8T"
      },
      "source": [
        "def train_epoch(model, data_loader, loss_fn, optimizer,scheduler, device, n_examples):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  \n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    targets = d[\"targets\"].long() \n",
        "    targets = targets.to(device)\n",
        "\n",
        "    outputs = model(x=input_ids)\n",
        "\n",
        "\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(torch.max(outputs, dim=1).indices == targets) \n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)\n",
        "\n",
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      targets = d[\"targets\"].long()\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      outputs = model(x=input_ids)\n",
        "      # print(outputs, targets)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(torch.max(outputs, dim=1).indices == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWeP0P6yGOhN",
        "outputId": "2f0e4954-24ae-4992-ebab-a7b6e7446df7"
      },
      "source": [
        "# history = defaultdict(list)\n",
        "# start_epoch = 0\n",
        "# best_accuracy = -1\n",
        "\n",
        "checkpoint = torch.load(\"./gdrive/MyDrive/Models/KimCNN/checkpoint.t7\")\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "start_epoch = checkpoint['epoch']\n",
        "\n",
        "print(start_epoch)\n",
        "\n",
        "\n",
        "# for epoch in range(EPOCHS):\n",
        "\n",
        "#   print(f'Epoch {start_epoch + epoch + 1}/{start_epoch + EPOCHS}')\n",
        "#   print('-' * 10)\n",
        "\n",
        "#   train_acc, train_loss = train_epoch(\n",
        "#     model,\n",
        "#     train_data_loader,    \n",
        "#     loss_fn, \n",
        "#     optimizer,\n",
        "#     scheduler, \n",
        "#     device, \n",
        "#     len(df_train)\n",
        "#   )\n",
        "\n",
        "#   print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "#   val_acc, val_loss = eval_model(\n",
        "#     model,\n",
        "#     val_data_loader,\n",
        "#     loss_fn, \n",
        "#     device, \n",
        "#     len(df_val)\n",
        "#   )\n",
        "\n",
        "#   # scheduler.step(val_acc)\n",
        "\n",
        "#   print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "#   print()\n",
        "\n",
        "#   history['train_acc'].append(train_acc)\n",
        "#   history['train_loss'].append(train_loss)\n",
        "#   history['val_acc'].append(val_acc)\n",
        "#   history['val_loss'].append(val_loss)\n",
        "\n",
        "#   if val_acc > best_accuracy:\n",
        "#     state = {\n",
        "#             'best_accuracy': val_acc,\n",
        "#             'epoch': start_epoch+epoch+1,\n",
        "#             'state_dict': model.state_dict(),\n",
        "#             'optimizer': optimizer.state_dict(),\n",
        "#     }\n",
        "#     savepath= \"./gdrive/MyDrive/Models/KimCNN/checkpoint.t7\"\n",
        "#     torch.save(state,savepath)\n",
        "#     best_accuracy = val_acc\n",
        "\n",
        "# state = {\n",
        "#         'epoch': start_epoch + EPOCHS,\n",
        "#         'state_dict': model.state_dict(),\n",
        "#         'optimizer': optimizer.state_dict(),\n",
        "# }\n",
        "# savepath= \"./gdrive/MyDrive/Models/KimCNN/checkpoint-{}.t7\".format(start_epoch + EPOCHS)\n",
        "# torch.save(state,savepath)\n",
        "\n",
        "# plt.plot(history['train_acc'], label='train accuracy')\n",
        "# plt.plot(history['val_acc'], label='validation accuracy')\n",
        "\n",
        "# plt.title('Training history')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.legend()\n",
        "# plt.ylim([0, 1]);"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "251\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGFmTSaxYMw-"
      },
      "source": [
        "state = {\n",
        "        'epoch': start_epoch + EPOCHS,\n",
        "        'state_dict': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "}\n",
        "savepath= \"./gdrive/MyDrive/Models/KimCNN/checkpoint-{}.t7\".format(start_epoch + EPOCHS)\n",
        "torch.save(state,savepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "wTzhGWp12XdE",
        "outputId": "020a8459-4fc5-4dfd-8457-8879a713726a"
      },
      "source": [
        "plt.plot(history['train_acc'], label='train accuracy')\n",
        "plt.plot(history['val_acc'], label='validation accuracy')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVh1s2cLCahH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c139c00-51ee-4ddb-ba1d-99f9b50994ef"
      },
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  \n",
        "  predictions = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      targets = d[\"targets\"].long()\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        x=input_ids,\n",
        "      )\n",
        "      preds = torch.max(outputs, dim=1).indices\n",
        "\n",
        "\n",
        "      predictions.extend(preds)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return predictions, real_values\n",
        "\n",
        "y_pred, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=['not_humanitarian', 'infrastructure_and_utility_damage', 'other_relevant_information', 'rescue_volunteering_or_donation_effort', 'affected_individuals'], digits = 4))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                        precision    recall  f1-score   support\n",
            "\n",
            "                      not_humanitarian     0.7039    0.8869    0.7849       504\n",
            "     infrastructure_and_utility_damage     0.7451    0.4691    0.5758        81\n",
            "            other_relevant_information     0.7118    0.5149    0.5975       235\n",
            "rescue_volunteering_or_donation_effort     0.7475    0.5873    0.6578       126\n",
            "                  affected_individuals     0.0000    0.0000    0.0000         9\n",
            "\n",
            "                              accuracy                         0.7120       955\n",
            "                             macro avg     0.5817    0.4916    0.5232       955\n",
            "                          weighted avg     0.7085    0.7120    0.6969       955\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}